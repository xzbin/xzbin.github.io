<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yoursite.com","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="个人以为：该模型确实具备了大一统的Level，模型的设计方面：简单、优美、有效。">
<meta property="og:type" content="article">
<meta property="og:title" content="Image as a Foreign Language: BEIT Pretraining for All Vision and Vision-Language Tasks">
<meta property="og:url" content="http://yoursite.com/2023/03/02/%E5%A4%9A%E6%A8%A1%E6%80%81-Image-as-a-Foreign-Language-BEIT-Pretraining-for-All-Vision-and-Vision-Language-Tasks/index.html">
<meta property="og:site_name" content="xzbin">
<meta property="og:description" content="个人以为：该模型确实具备了大一统的Level，模型的设计方面：简单、优美、有效。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://yoursite.com/2023/03/02/%E5%A4%9A%E6%A8%A1%E6%80%81-Image-as-a-Foreign-Language-BEIT-Pretraining-for-All-Vision-and-Vision-Language-Tasks/beit3.png">
<meta property="og:image" content="http://yoursite.com/2023/03/02/%E5%A4%9A%E6%A8%A1%E6%80%81-Image-as-a-Foreign-Language-BEIT-Pretraining-for-All-Vision-and-Vision-Language-Tasks/beit3_2.png">
<meta property="og:image" content="http://yoursite.com/2023/03/02/%E5%A4%9A%E6%A8%A1%E6%80%81-Image-as-a-Foreign-Language-BEIT-Pretraining-for-All-Vision-and-Vision-Language-Tasks/beit3_1.png">
<meta property="og:image" content="http://yoursite.com/2023/03/02/%E5%A4%9A%E6%A8%A1%E6%80%81-Image-as-a-Foreign-Language-BEIT-Pretraining-for-All-Vision-and-Vision-Language-Tasks/beit3_3.png">
<meta property="og:image" content="http://yoursite.com/2023/03/02/%E5%A4%9A%E6%A8%A1%E6%80%81-Image-as-a-Foreign-Language-BEIT-Pretraining-for-All-Vision-and-Vision-Language-Tasks/beit3_4.png">
<meta property="og:image" content="http://yoursite.com/2023/03/02/%E5%A4%9A%E6%A8%A1%E6%80%81-Image-as-a-Foreign-Language-BEIT-Pretraining-for-All-Vision-and-Vision-Language-Tasks/beit3_5.png">
<meta property="og:image" content="http://yoursite.com/2023/03/02/%E5%A4%9A%E6%A8%A1%E6%80%81-Image-as-a-Foreign-Language-BEIT-Pretraining-for-All-Vision-and-Vision-Language-Tasks/beit3_6.png">
<meta property="og:image" content="http://yoursite.com/2023/03/02/%E5%A4%9A%E6%A8%A1%E6%80%81-Image-as-a-Foreign-Language-BEIT-Pretraining-for-All-Vision-and-Vision-Language-Tasks/beit3_7.png">
<meta property="article:published_time" content="2023-03-02T10:37:04.000Z">
<meta property="article:modified_time" content="2025-03-06T14:50:52.872Z">
<meta property="article:author" content="xzbin">
<meta property="article:tag" content="BEit3">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/2023/03/02/%E5%A4%9A%E6%A8%A1%E6%80%81-Image-as-a-Foreign-Language-BEIT-Pretraining-for-All-Vision-and-Vision-Language-Tasks/beit3.png">

<link rel="canonical" href="http://yoursite.com/2023/03/02/%E5%A4%9A%E6%A8%A1%E6%80%81-Image-as-a-Foreign-Language-BEIT-Pretraining-for-All-Vision-and-Vision-Language-Tasks/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Image as a Foreign Language: BEIT Pretraining for All Vision and Vision-Language Tasks | xzbin</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">xzbin</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-首页">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-文章">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>文章</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-分类">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-关于">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2023/03/02/%E5%A4%9A%E6%A8%A1%E6%80%81-Image-as-a-Foreign-Language-BEIT-Pretraining-for-All-Vision-and-Vision-Language-Tasks/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="xzbin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="xzbin">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Image as a Foreign Language: BEIT Pretraining for All Vision and Vision-Language Tasks
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-03-02 10:37:04" itemprop="dateCreated datePublished" datetime="2023-03-02T10:37:04+00:00">2023-03-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-03-06 14:50:52" itemprop="dateModified" datetime="2025-03-06T14:50:52+00:00">2025-03-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%A4%9A%E6%A8%A1%E6%80%81/" itemprop="url" rel="index"><span itemprop="name">多模态</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>个人以为：该模型确实具备了大一统的<code>Level</code>，模型的设计方面：简单、优美、有效。</p>
<hr>
<ul>
<li>原始论文: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2208.10442">Image as a Foreign Language: BEIT Pretraining for All Vision and Vision-Language Tasks</a></li>
</ul>
<h1 id="文章idea"><a href="#文章idea" class="headerlink" title="文章idea"></a>文章idea</h1><ul>
<li>将<code>image</code>也看做是一种语言:<code>foreign language</code>。</li>
<li>没有使用多任务损失，因为作者认为这对模型是一种阻碍。因此仅仅使用一个损失。</li>
</ul>
<h1 id="文章主旨"><a href="#文章主旨" class="headerlink" title="文章主旨"></a>文章主旨</h1><ul>
<li>号称多模态进入了大一统的时代，提出了<code>BEiT-3</code>模型。</li>
<li>与其他多模态模型不同，该模型只使用了 <code>MASK</code> 损失：<code>MASK language model: MLM</code>、<code>mask image model: MIM</code>。</li>
</ul>
<h1 id="模型细节"><a href="#模型细节" class="headerlink" title="模型细节"></a>模型细节</h1><p><img src="./beit3.png" alt="beit3.png"></p>
<ul>
<li>模型并没有直接使用<code>transfomer</code>，而是使用了一种改进版本<code>Multiway Transformer</code>，该结构是对<code>transformer</code>的升级，具体细节此处不做赘述，请见另一篇博客：<a href="/2023/02/28/VLMO-Unified-Vision-Language-Pre-Training-with-Mixture-of-Modality-Experts/">VLMo</a></li>
<li>数据处理：文本的<code>token</code>处理使用的是<code>SentencePiece</code>，并且会随机 <code>MASK</code>掉<code>15%</code>的<code>token</code>。</li>
<li>图像的<code>token</code>化使用的是<code>patch</code>，<code>target</code> 并不是被<code>MASK</code>掉的<code>patch</code>，而是另外一种<code>token</code>化的方式，此处与<code>BEIT v2</code> 相同。<code>MASK</code>策略：<code>40% of image patches using a  lock-wise masking strategy as in BEIT</code>。</li>
<li><p>模态数据：<code>50% tokens of texts from image-text pairs</code> + <code>40% of image patches</code></p>
</li>
<li><p><code>BEiT v3</code>是非常大的模型,与<code>VLMo</code>所有层均使用了相同结构不同，其稍微做了调整：<code>All layers contain both vision experts and language experts. Vision-language experts are also employed in the top three Multiway
Transformer layers</code></p>
</li>
<li><p>实现细节：<code>Each batch contains 6144 samples in
total, including 2048 images, 2048 texts and 2048 image-text pairs</code></p>
</li>
<li><p>与其他多模态模型动辄多个<code>loss</code>的实现不同，该模型只有一个基于<code>MASK loss</code>。</p>
</li>
</ul>
<h2 id="模型的使用方式"><a href="#模型的使用方式" class="headerlink" title="模型的使用方式"></a>模型的使用方式</h2><p><img src="./beit3_2.png" alt="beit3_2.png"></p>
<ul>
<li><code>BEIT-3</code>有多种使用方式，既可以当<code>dual encoder</code>，也可以用作<code>fusion encoder</code>；既可以只用以完成文本相关任务，可以只用以完成图像相关任务。下图是<code>V+L</code>相关的几种任务，其中<code>a</code>,<code>b</code>,<code>c</code>,<code>d</code>均是常见任务不做赘述。</li>
<li>但是<code>e</code>属于生成任务，原则上来讲普通的<code>attention</code>不能实现。但是这部分的细节在<code>Image Captioning</code> 一节中有相关描述，可以理解成使用了 <code>mask self attention</code>的思路，使得文本<code>token</code>只能看到其左边的<code>token</code>，不能看到右边没有生成的数据。这样就可以实现生成任务了，文中具体表述：<code>BEIT-3 is used as a conditional generation model via masked finetuning. To be more specific, a special self-attention mask is employed for the image captioning task. Image tokens (i.e., image patches) can only attend to each other bidirectionally within the image sequence. Tokens of the caption can attention to image tokens, their leftward caption tokens, and themselves.</code></li>
</ul>
<h1 id="模型试验"><a href="#模型试验" class="headerlink" title="模型试验"></a>模型试验</h1><h2 id="数据集："><a href="#数据集：" class="headerlink" title="数据集："></a>数据集：</h2><p><img src="./beit3_1.png" alt="beit3_1.png"></p>
<h2 id="Vision-Language-Downstream-Tasks"><a href="#Vision-Language-Downstream-Tasks" class="headerlink" title="Vision-Language Downstream Tasks"></a>Vision-Language Downstream Tasks</h2><p><img src="./beit3_3.png" alt="beit3_3.png"></p>
<h3 id="VQA"><a href="#VQA" class="headerlink" title="VQA"></a>VQA</h3><p>对<code>BEIT-3</code> 进行调整以实现VQA任务，具体细节：<br><code>BEIT-3 is finetuned as a fusion encoder to model deep interactions of images and questions for the VQA task. We concatenate the embeddings of a given question and an image, and then feed the input embeddings into Multiway Transformers to jointly encode the image-question pair. The final pooled output is fed into a classifier layer to predict the answer</code></p>
<h3 id="Visual-Reasoning"><a href="#Visual-Reasoning" class="headerlink" title="Visual Reasoning"></a>Visual Reasoning</h3><p>对<code>BEIT-3</code> 进行调整以实现<code>NLVR2</code>任务，具体细节：<br><code>we construct two image-text pairs based on the triplet input. We finetune BEIT-3 as a fusion encoder to jointly encode the image-text pairs. The final pooled outputs of the two pairs are concatenated and then fed into a classifier layer to predict the label</code></p>
<h3 id="Image-Captioning"><a href="#Image-Captioning" class="headerlink" title="Image Captioning"></a>Image Captioning</h3><p>使用了<code>mask</code>机制，使得该模型可以实现生成任务。</p>
<h3 id="Image-Text-Retrieval"><a href="#Image-Text-Retrieval" class="headerlink" title="Image-Text Retrieval"></a>Image-Text Retrieval</h3><p>使用<code>dual encoder</code>的思路，文中描述是：<code>Dual-encoder models separately encode images and texts to obtain their representations. Then we calculate the cosine similarity scores of these representations</code><br><img src="./beit3_4.png" alt="beit3_4.png"></p>
<h2 id="Vision-Downstream-Tasks"><a href="#Vision-Downstream-Tasks" class="headerlink" title="Vision Downstream Tasks"></a>Vision Downstream Tasks</h2><h3 id="Object-Detection-and-Instance-Segmentation"><a href="#Object-Detection-and-Instance-Segmentation" class="headerlink" title="Object Detection and Instance Segmentation"></a>Object Detection and Instance Segmentation</h3><p>利用<code>ViTDet</code>的框架，将<code>BEIT-3</code> 作为<code>backbone</code>，<code>Soft-NMS</code>。 数据集：<code>COCO</code><br><img src="./beit3_5.png" alt="beit3_5.png"></p>
<h3 id="Semantic-Segmentation"><a href="#Semantic-Segmentation" class="headerlink" title="Semantic Segmentation"></a>Semantic Segmentation</h3><p><code>Semantic segmentation aims to predict the label for each pixel of the given image</code><br>利用<code>Mask2Former</code>的框架，数据集：<code>ADE20K</code><br><img src="./beit3_6.png" alt="beit3_6.png"></p>
<h3 id="Image-Classification"><a href="#Image-Classification" class="headerlink" title="Image Classification"></a>Image Classification</h3><p>数据集：<code>ImageNet-1K</code>。但是实现方式不是传统意义上的多分类任务，而是检索任务来实现：<code>image-to-text retrieval</code>. 将类别名当做文本，构建了<code>image-text pairs</code>。利用<code>dual encoder</code>完成构建模型，然后分别提取<code>embedding</code>，利用<code>cosine similarity scores</code> 预测最相关的标签。<br><img src="./beit3_7.png" alt="beit3_7.png"></p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/BEit3/" rel="tag"># BEit3</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2023/03/01/BEIT-BERT-Pre-Training-of-Image-Transformers/" rel="prev" title="BEIT: BERT Pre-Training of Image Transformers">
      <i class="fa fa-chevron-left"></i> BEIT: BERT Pre-Training of Image Transformers
    </a></div>
      <div class="post-nav-item">
    <a href="/2023/03/03/torchFM-%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%E7%B3%BB%E5%88%97-wide-deep/" rel="next" title="Wide & Deep Learning for Recommender Systems">
      Wide & Deep Learning for Recommender Systems <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%96%87%E7%AB%A0idea"><span class="nav-number">1.</span> <span class="nav-text">文章idea</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%96%87%E7%AB%A0%E4%B8%BB%E6%97%A8"><span class="nav-number">2.</span> <span class="nav-text">文章主旨</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E7%BB%86%E8%8A%82"><span class="nav-number">3.</span> <span class="nav-text">模型细节</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E5%BC%8F"><span class="nav-number">3.1.</span> <span class="nav-text">模型的使用方式</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E8%AF%95%E9%AA%8C"><span class="nav-number">4.</span> <span class="nav-text">模型试验</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%9A"><span class="nav-number">4.1.</span> <span class="nav-text">数据集：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Vision-Language-Downstream-Tasks"><span class="nav-number">4.2.</span> <span class="nav-text">Vision-Language Downstream Tasks</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#VQA"><span class="nav-number">4.2.1.</span> <span class="nav-text">VQA</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Visual-Reasoning"><span class="nav-number">4.2.2.</span> <span class="nav-text">Visual Reasoning</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Image-Captioning"><span class="nav-number">4.2.3.</span> <span class="nav-text">Image Captioning</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Image-Text-Retrieval"><span class="nav-number">4.2.4.</span> <span class="nav-text">Image-Text Retrieval</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Vision-Downstream-Tasks"><span class="nav-number">4.3.</span> <span class="nav-text">Vision Downstream Tasks</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Object-Detection-and-Instance-Segmentation"><span class="nav-number">4.3.1.</span> <span class="nav-text">Object Detection and Instance Segmentation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Semantic-Segmentation"><span class="nav-number">4.3.2.</span> <span class="nav-text">Semantic Segmentation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Image-Classification"><span class="nav-number">4.3.3.</span> <span class="nav-text">Image Classification</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">xzbin</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">34</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">30</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">xzbin</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
