<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yoursite.com","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="原始论文: PP-OCR: A Practical Ultra Lightweight OCR System  PP-OCR 在识别6622个中文字符模型尺寸有3.5M，63个字母数字符号的模型有2.8M。该论文在增强模型能力和减少模型尺寸方面做了很多尝试。同时随着论文放出了多个模型英文和中文模型，其中包括text detector【97K images are used】、direction">
<meta property="og:type" content="article">
<meta property="og:title" content="PP-OCR: A Practical Ultra Lightweight OCR System">
<meta property="og:url" content="http://yoursite.com/2022/02/05/PP-OCR-A-Practical-Ultra-Lightweight-OCR-System/index.html">
<meta property="og:site_name" content="xzbin">
<meta property="og:description" content="原始论文: PP-OCR: A Practical Ultra Lightweight OCR System  PP-OCR 在识别6622个中文字符模型尺寸有3.5M，63个字母数字符号的模型有2.8M。该论文在增强模型能力和减少模型尺寸方面做了很多尝试。同时随着论文放出了多个模型英文和中文模型，其中包括text detector【97K images are used】、direction">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://yoursite.com/2022/02/05/PP-OCR-A-Practical-Ultra-Lightweight-OCR-System/scene_documnet_text.png">
<meta property="og:image" content="http://yoursite.com/2022/02/05/PP-OCR-A-Practical-Ultra-Lightweight-OCR-System/ppocr_framework.png">
<meta property="og:image" content="http://yoursite.com/2022/02/05/PP-OCR-A-Practical-Ultra-Lightweight-OCR-System/db_framework.png">
<meta property="og:image" content="http://yoursite.com/2022/02/05/PP-OCR-A-Practical-Ultra-Lightweight-OCR-System/backbone_time_acc.png">
<meta property="og:image" content="http://yoursite.com/2022/02/05/PP-OCR-A-Practical-Ultra-Lightweight-OCR-System/cosine_lr.png">
<meta property="og:image" content="http://yoursite.com/2022/02/05/PP-OCR-A-Practical-Ultra-Lightweight-OCR-System/improved_PACT.png">
<meta property="og:image" content="http://yoursite.com/2022/02/05/PP-OCR-A-Practical-Ultra-Lightweight-OCR-System/TIA.png">
<meta property="og:image" content="http://yoursite.com/2022/02/05/PP-OCR-A-Practical-Ultra-Lightweight-OCR-System/mobileNetV3_framework.png">
<meta property="og:image" content="http://yoursite.com/2022/02/05/PP-OCR-A-Practical-Ultra-Lightweight-OCR-System/dataset_details.png">
<meta property="og:image" content="http://yoursite.com/2022/02/05/PP-OCR-A-Practical-Ultra-Lightweight-OCR-System/Implementation_details.png">
<meta property="article:published_time" content="2022-02-05T15:48:36.000Z">
<meta property="article:modified_time" content="2025-03-06T14:50:52.808Z">
<meta property="article:author" content="xzbin">
<meta property="article:tag" content="OCR">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/2022/02/05/PP-OCR-A-Practical-Ultra-Lightweight-OCR-System/scene_documnet_text.png">

<link rel="canonical" href="http://yoursite.com/2022/02/05/PP-OCR-A-Practical-Ultra-Lightweight-OCR-System/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>PP-OCR: A Practical Ultra Lightweight OCR System | xzbin</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">xzbin</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-首页">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-文章">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>文章</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-分类">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-关于">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2022/02/05/PP-OCR-A-Practical-Ultra-Lightweight-OCR-System/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="xzbin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="xzbin">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          PP-OCR: A Practical Ultra Lightweight OCR System
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-02-05 15:48:36" itemprop="dateCreated datePublished" datetime="2022-02-05T15:48:36+00:00">2022-02-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-03-06 14:50:52" itemprop="dateModified" datetime="2025-03-06T14:50:52+00:00">2025-03-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <ul>
<li>原始论文: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2009.09941">PP-OCR: A Practical Ultra Lightweight OCR System</a></li>
</ul>
<p><code>PP-OCR</code> 在识别6622个中文字符模型尺寸有<code>3.5M</code>，63个字母数字符号的模型有<code>2.8M</code>。该论文在增强模型能力和减少模型尺寸方面做了很多尝试。同时随着论文放出了多个模型英文和中文模型，其中包括<code>text detector【97K images are used】</code>、<code>direction classifier【600K images are used】</code>、<code>text recognizer【17.9M images are used】</code></p>
<p>文本出现的多种形态：<code>scene text and documen text</code>。<code>scene text</code>: 自然场景中的文本，通常会因透视、缩放、弯曲、杂乱、字体、多语言、模糊、照明等因素而发生显著变化；<code>documen text</code>: 在实际应用中更为常见。举例如下：<img src="./scene_documnet_text.png" alt="scene_documnet_text"></p>
<p><code>Computational Efficiency</code> 是OCR系统的重要指标。</p>
<h1 id="PP-OCR框架示意图"><a href="#PP-OCR框架示意图" class="headerlink" title="PP-OCR框架示意图"></a><code>PP-OCR</code>框架示意图</h1><p><code>PP-OCR</code>是由三部分组成：<code>text detection</code>，<code>detected boxes rectification</code>，<code>text recognition</code>。具体如下图所示：<br><img src="./ppocr_framework.png" alt="ppocr_framework"></p>
<h2 id="Text-Detection"><a href="#Text-Detection" class="headerlink" title="Text Detection"></a>Text Detection</h2><p>这部分主要作用是定位图片中文本区域，我们使用的是<code>Differentiable Binarization</code>【基于分割的思想】作为<code>text detector</code>。为了更好的提高效果和效率，使用了以下6个策略：<code>light backbone, light head, remove SE module, cosine learning rate decay, learning rate warm-up, and FPGM pruner</code>。最终这部分模型尺寸较少到<code>1.4M</code>。<br>Architecture of the text detector DB:<br><img src="./db_framework.png" alt="db_framework"></p>
<h2 id="Detection-Boxes-Rectify"><a href="#Detection-Boxes-Rectify" class="headerlink" title="Detection Boxes Rectify"></a>Detection Boxes Rectify</h2><p><code>text box</code>需要被转换成水平矩形，才可以进行后续的<code>Text Recognition</code>。通过<code>几何变换</code>就可以较为简单得实现这种变换。但是也有可能导致翻转。因此此分类器需要判断出<code>text box</code>的方向。为了更好的提高效果和效率，使用了以下4个策略：<code>light backbone, data augmentation, input resolution and PACT quantization</code>。 最终, 模型大小：500KB</p>
<h2 id="Text-Recognition"><a href="#Text-Recognition" class="headerlink" title="Text Recognition"></a>Text Recognition</h2><p>我们使用<code>CRNN</code>作为<code>Text Recognition</code>。该模型被广泛的使用。<code>CRNN</code>集成了特征抽取和序列模型，使用了<code>CTC loss</code>。为了更好的提高效果和效率，使用了以下4个策略：<code>light backbone, data augmentation, cosine learning rate decay, feature map resolution, regularization parameters, learning rate warm-up, light head, pre-trained model and PACT quantization</code>。中英文识别模型大小：<code>1.6M</code>, 数字字母模型大小：<code>1.6M</code></p>
<p>训练各个模型大小所使用的数据集：<code>text detection dataset has 97K images. Direction classification dataset has 600k images. Text recognition dataset has 17.9M images</code></p>
<h1 id="Enhancement-or-Slimming-Strategies"><a href="#Enhancement-or-Slimming-Strategies" class="headerlink" title="Enhancement or Slimming Strategies"></a>Enhancement or Slimming Strategies</h1><h2 id="Text-Detection-1"><a href="#Text-Detection-1" class="headerlink" title="Text Detection"></a>Text Detection</h2><h3 id="Light-Backbone"><a href="#Light-Backbone" class="headerlink" title="Light Backbone"></a>Light Backbone</h3><p><code>backbone</code>的大小是模型大小的主要影响因素。随着图片分类的发展，<code>MobileNetV1</code>、<code>MobileNetV2</code>、<code>MobileNetV3</code>和<code>ShuffleNetV2</code>系列是常用的轻量级<code>backbone</code>。<a target="_blank" rel="noopener" href="https://github.com/PaddlePaddle/PaddleClas/">PaddleClas</a>提供了超过20种<code>backbone</code>在<code>CPU</code>上的推理时间和精度。论文中采用了<code>MobileNetV3 large x0.5</code>为<code>backbone</code>。<br><img src="./backbone_time_acc.png" alt="backbone_time_acc"></p>
<h3 id="Light-Head"><a href="#Light-Head" class="headerlink" title="Light Head"></a>Light Head</h3><p><code>Text Detection</code>的头部与<code>FPN</code>在目标检测中的架构类似，并融合不同尺度的特征映射，以增强小文本区域检测的效果。<code>inner channels</code>对模型尺寸有很大影响，当从256减少到96时，模型尺寸从<code>7M</code>减少到<code>4.1M</code>，但是精度略有下降。</p>
<h3 id="Remove-SE"><a href="#Remove-SE" class="headerlink" title="Remove SE"></a>Remove SE</h3><p><code>SE</code>的全称是<code>squeeze-and-excitation</code>。<code>SE</code>可以明显提高视觉任务的准确性，但是<code>MobileNetV3</code>包含了很多<code>SE</code>模块。但是当输入分辨率较大时，比如<code>640 × 640</code>,<code>SE</code>模块对精度的提高有限，但是时间花费特别巨大。当移除了<code>SE</code>模块后，模型尺寸从<code>4.1M</code>减少到<code>2.5M</code>。但是精度没有影响。</p>
<h3 id="Cosine-Learning-Rate-Decay"><a href="#Cosine-Learning-Rate-Decay" class="headerlink" title="Cosine Learning Rate Decay"></a>Cosine Learning Rate Decay</h3><p><code>Learning Rate</code>用来控制<code>learning speed</code>，在训练的早期，模型权重处于随机初始化状态，可以设置一个较大的学习率加快收敛。在训练的后期，权重接近最优值，可以设置一个较小的学习率。<code>Cosine learning rate decay</code>是一个非常好的选择。与<code>piecewise decay</code>对比：<img src="./cosine_lr.png" alt="cosine_lr"></p>
<h3 id="Learning-Rate-Warm-up"><a href="#Learning-Rate-Warm-up" class="headerlink" title="Learning Rate Warm-up"></a>Learning Rate Warm-up</h3><p><code>learning rate warm-up</code>提高了分类模型的精度。模型刚开始训练的时候，使用较大的学习率会变得不稳定的，因此学习率应当设置很低。</p>
<h3 id="FPGM-Pruner"><a href="#FPGM-Pruner" class="headerlink" title="FPGM Pruner"></a>FPGM Pruner</h3><p><code>Pruning</code>是另外一个提高模型性能的方法，为了避免模型性能下降，我们采用了<code>FPGM Pruner</code>找到不重要的子网络，每层的压缩比对于修剪模型也很重要，均匀修剪每一层通常会导致性能显著下降。</p>
<h2 id="Direction-Classification"><a href="#Direction-Classification" class="headerlink" title="Direction Classification"></a>Direction Classification</h2><p>本部分介绍了一些增强模型性能和减少<code>direction classifier</code>模型尺寸的方法</p>
<h3 id="Light-Backbone-1"><a href="#Light-Backbone-1" class="headerlink" title="Light Backbone"></a>Light Backbone</h3><p>使用<code>MobileNetV3</code> 作为 <code>backbone</code>，与<code>text detector</code>相同。我们使用了<code>MobileNetV3 small x0.35</code>平衡了精度与效率，如果使用较大的<code>backbone</code>，精度并没有提升。</p>
<h3 id="Data-Augmentation"><a href="#Data-Augmentation" class="headerlink" title="Data Augmentation"></a>Data Augmentation</h3><p>常用的数据增强手段：旋转、透视失真、运动模糊和高斯噪声。这些过程一般称为<code>DBA【Base Data Augmentation】</code>.图像分类任务中，提出了一些新的数据增强操作。比如：<code>AutoAugmentAutoAugment, RandAugment, CutOut, RandErasing, HideAndSeek, GridMask, Mixup,and Cutmix</code>。但是在实验表明，多数操作对<code>direction classifier</code>没有作用，除了<code>RandAugment and RandErasing. RandAugment</code>。最终，我们使用了<code>BDA</code>和<code>RandAugment</code>用于训练<code>direction classifier</code>。</p>
<h3 id="Input-Resolution"><a href="#Input-Resolution" class="headerlink" title="Input Resolution"></a>Input Resolution</h3><p>一般来说，当图像的分辨率增加时，精度也会提高。由于<code>backbone</code>非常轻，适当提高分辨率不会导致计算时间明显增加。在之前的<code>text recognition</code>任务中，图像的高度和宽度分别是32和100；在<code>PP-OCR</code>中，图像的高度和宽度分别设置是48和192。</p>
<h3 id="PACT-Quantization"><a href="#PACT-Quantization" class="headerlink" title="PACT Quantization"></a>PACT Quantization</h3><p><code>Quantization</code>使神经网络工作模型具有更低的延迟、更小的体积和更低的计算功耗。目前，量化主要分为两类：离线量化和在线量化。离线量化是指：使用<code>KL divergence</code>和<code>moving average</code>等方法来确定量化参数，并且不需要重新训练。在线量化是指：在训练过程中确定量化参数，它可以提供比离线量化模式更少的量化损耗。</p>
<p><code>PACT (PArameterized Clipping acTivation)</code>是一种在线量化的方法，可提前从激活值中移除一些异常值。剔除异常值后，该模型可以学习更合适的值。</p>
<p><code>普通PACT</code>方法的激活值预处理基于<code>ReLU</code>函数,但是在<code>MobileNetV3</code>中除了<code>ReLU</code>还有<code>hard swish</code>。使用普通PACT量化会导致更高的量化损耗。因此，我们对激活预处理公式进行修改，具体如下图所示：<img src="./improved_PACT.png" alt="improved_PACT"></p>
<p>我们使用改进的PACT量化方法对方向分类器模型进行量化，<code>FPGM Pruner</code>和<code>PACT quantization</code>都是基于<code>PaddleSlim</code>。<code>PaddleSlim</code>是一个模型压缩工具箱，其包含了一系列的压缩方法，比如<code>pruning</code>, <code>fixed point quantization</code>, <code>knowledge distillation</code>, <code>hyperparameter searching neural architecture search</code>。</p>
<h2 id="Text-Recognition-1"><a href="#Text-Recognition-1" class="headerlink" title="Text Recognition"></a>Text Recognition</h2><p>本部分介绍了一些增强模型性能和减少<code>Text Recognition</code>模型尺寸的方法</p>
<h3 id="Light-Backbone-2"><a href="#Light-Backbone-2" class="headerlink" title="Light Backbone"></a>Light Backbone</h3><p>此处也是使用了<code>MobileNetV3</code>，如果对模型尺寸不敏感，<code>MobileNetV3 small x1.0</code>也是一个不错的选择，模型大小虽然增加了<code>2M</code>,但是精度却有明显提升。</p>
<h3 id="Data-Augmentation-1"><a href="#Data-Augmentation-1" class="headerlink" title="Data Augmentation"></a>Data Augmentation</h3><p>在早期的<code>text recognition</code>任务中，<code>BDA</code>经常被使用。现在的<code>text recognition</code>任务中<code>TIA</code>也是经常用到的。首先，在图像上初始化一组基准点。然后随机移动这些点，通过几何变换生成新图像。在<code>PP-OCR</code>中的<code>text recognition</code>，我们使用了<code>BDA</code>和<code>TIA</code>两种数据增强方式。<code>TIA</code>介绍：<img src="TIA.png" alt="TIA"></p>
<h3 id="Cosine-Learning-Rate-Decay-1"><a href="#Cosine-Learning-Rate-Decay-1" class="headerlink" title="Cosine Learning Rate Decay"></a>Cosine Learning Rate Decay</h3><p><code>Cosine Learning Rate Decay</code>已成为首选的学习率降低方法。实验表明，余弦学习速率衰减策略也能有效地提高<code>text recognition</code>的模型能力。</p>
<h3 id="Feature-Map-Resolution"><a href="#Feature-Map-Resolution" class="headerlink" title="Feature Map Resolution"></a>Feature Map Resolution</h3><p><code>CRNN</code>输入的高度和宽度设置为32和320，因此，原始<code>MobileNetV3</code>的步幅不适合文本识别。需要针对特定层的步幅进行调整，具体如下图所示：<img src="./mobileNetV3_framework.png" alt="mobileNetV3_framework"></p>
<h3 id="Regularization-Parameters"><a href="#Regularization-Parameters" class="headerlink" title="Regularization Parameters"></a>Regularization Parameters</h3><p>为了避免过拟合，许多正则化的方式被提出，<code>weight decay</code>是最被广泛使用的一种，在损失函数中增加<code>L2 regularization</code>。在L2正则化的帮助下，网络的权重趋向于选择较小的值，最终整个网络中的参数趋向于0，模型的泛化性能也相应提高。对于文本识别，<code>L2 decay</code>对<code>Text Recognition</code>的准确性有很大影响。</p>
<h3 id="Learning-Rate-Warm-up-1"><a href="#Learning-Rate-Warm-up-1" class="headerlink" title="Learning Rate Warm-up"></a>Learning Rate Warm-up</h3><p>实验表明使用该策略也是有效的</p>
<h3 id="Light-Head-1"><a href="#Light-Head-1" class="headerlink" title="Light Head"></a>Light Head</h3><p>全连接层用于将序列特征编码为预测字符。序列特征的维数对模型大小有影响，尤其是对于6000多个字符的中文识别。同时，并不是维度越高，序列特征表征能力越强。在<code>PP-OCR</code>中，序列特征的维数设置为48.</p>
<h3 id="Pre-trained-Model"><a href="#Pre-trained-Model" class="headerlink" title="Pre-trained Model"></a>Pre-trained Model</h3><p>如果训练数据较少，则对现有网络进行微调。图像分类和目标检测中的迁移学习表明了上述策略的有效性。在真实场景中，训练数据通常是有限的。如果使用数千万个样本对模型进行训练，即使它们是合成的，使用上述模型也可以显著提高精度。</p>
<h3 id="PACT-Quantization-1"><a href="#PACT-Quantization-1" class="headerlink" title="PACT Quantization"></a>PACT Quantization</h3><p>我们使用了与<code>direction classification</code>相似的<code>Quantization</code>方式减少模型尺寸，但是跳过了<code>LSTM</code>层。由于LSTM量化的复杂性，目前不会对这些层进行量化。</p>
<h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><h2 id="3-1-Experimental-Setup"><a href="#3-1-Experimental-Setup" class="headerlink" title="3.1 Experimental Setup"></a>3.1 Experimental Setup</h2><p>对于 <code>text detection</code>，有<code>97k</code>个训练图像和<code>500</code>个验证图像。在训练图像中，<code>68K</code>是真实场景图像，其来自一些公共数据集和百度图像搜索。剩下的<code>29K</code>是合成图像，其主要集中在长文本、多方向文本和表格文本的场景。所有验证图像均来自真实场景。</p>
<p>在<code>direction classification</code>中，有<code>600k</code>训练图像和<code>310K</code>验证图像。训练图像中，<code>100K</code>是真实场景图像，来自公开数据集（<code>LSVT, RCTW-17, MTWI 2018</code>），主要是水平文本。剩余的<code>500K</code>合成图像主要集中在反向文本上，我们使用垂直字体合成一些文本图像，然后水平旋转它们。所有验证图像均来自真实场景。</p>
<p>在<code>text recognition</code>中，有<code>17.9M</code>训练图像和<code>18.7K</code>验证图像。在训练数据中，有<code>1.9M</code>是真实场景图像，来自公开数据集（<code>LSVT, RCTW-17, MTWI 2018 and CCPD 2019</code>）。剩下的<code>16M</code>数据来自于合成数据，主要关注不同背景的场景、平移、旋转、透视变换、线条干扰、噪声、垂直文本等。合成图像的语料库来源于真实场景图像。所有验证图像也都来自真实场景。</p>
<p>数据集细节: <img src="./dataset_details.png" alt="dataset_details"></p>
<h2 id="Implementation-Details"><a href="#Implementation-Details" class="headerlink" title="Implementation Details"></a>Implementation Details</h2><p>我们使用<code>Adam</code>优化器训练所有模型，并且使用<code>cosine learning rate decay</code>作为学习率调度。使用<code>FPGM pruner</code>和<code>PACT quantization</code>用来减少模型尺寸。训练时候的参数细节: <img src="./Implementation_details.png" alt="Implementation_details"></p>
<p>在推理阶段，<code>HMean</code>用于评估<code>text detector</code>的性能。<code>Accuracy</code>用于评估<code>direction classifier</code>或<code>text recognizer</code>的性能。<code>F-score</code>用于评估OCR系统的性能。为了计算<code>F-score</code>应该考虑：准确的位置和相同的文本。</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/OCR/" rel="tag"># OCR</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/09/19/faiss-%E4%BB%8B%E7%BB%8D/" rel="prev" title="faiss 介绍">
      <i class="fa fa-chevron-left"></i> faiss 介绍
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/05/03/%E5%AF%B9%E7%8E%8B%E8%80%85%E8%8D%A3%E8%80%80%E7%90%86%E8%A7%A3/" rel="next" title="对王者荣耀理解">
      对王者荣耀理解 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#PP-OCR%E6%A1%86%E6%9E%B6%E7%A4%BA%E6%84%8F%E5%9B%BE"><span class="nav-number">1.</span> <span class="nav-text">PP-OCR框架示意图</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Text-Detection"><span class="nav-number">1.1.</span> <span class="nav-text">Text Detection</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Detection-Boxes-Rectify"><span class="nav-number">1.2.</span> <span class="nav-text">Detection Boxes Rectify</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Text-Recognition"><span class="nav-number">1.3.</span> <span class="nav-text">Text Recognition</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Enhancement-or-Slimming-Strategies"><span class="nav-number">2.</span> <span class="nav-text">Enhancement or Slimming Strategies</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Text-Detection-1"><span class="nav-number">2.1.</span> <span class="nav-text">Text Detection</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Light-Backbone"><span class="nav-number">2.1.1.</span> <span class="nav-text">Light Backbone</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Light-Head"><span class="nav-number">2.1.2.</span> <span class="nav-text">Light Head</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Remove-SE"><span class="nav-number">2.1.3.</span> <span class="nav-text">Remove SE</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Cosine-Learning-Rate-Decay"><span class="nav-number">2.1.4.</span> <span class="nav-text">Cosine Learning Rate Decay</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Learning-Rate-Warm-up"><span class="nav-number">2.1.5.</span> <span class="nav-text">Learning Rate Warm-up</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#FPGM-Pruner"><span class="nav-number">2.1.6.</span> <span class="nav-text">FPGM Pruner</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Direction-Classification"><span class="nav-number">2.2.</span> <span class="nav-text">Direction Classification</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Light-Backbone-1"><span class="nav-number">2.2.1.</span> <span class="nav-text">Light Backbone</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Data-Augmentation"><span class="nav-number">2.2.2.</span> <span class="nav-text">Data Augmentation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Input-Resolution"><span class="nav-number">2.2.3.</span> <span class="nav-text">Input Resolution</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#PACT-Quantization"><span class="nav-number">2.2.4.</span> <span class="nav-text">PACT Quantization</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Text-Recognition-1"><span class="nav-number">2.3.</span> <span class="nav-text">Text Recognition</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Light-Backbone-2"><span class="nav-number">2.3.1.</span> <span class="nav-text">Light Backbone</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Data-Augmentation-1"><span class="nav-number">2.3.2.</span> <span class="nav-text">Data Augmentation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Cosine-Learning-Rate-Decay-1"><span class="nav-number">2.3.3.</span> <span class="nav-text">Cosine Learning Rate Decay</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Feature-Map-Resolution"><span class="nav-number">2.3.4.</span> <span class="nav-text">Feature Map Resolution</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Regularization-Parameters"><span class="nav-number">2.3.5.</span> <span class="nav-text">Regularization Parameters</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Learning-Rate-Warm-up-1"><span class="nav-number">2.3.6.</span> <span class="nav-text">Learning Rate Warm-up</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Light-Head-1"><span class="nav-number">2.3.7.</span> <span class="nav-text">Light Head</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Pre-trained-Model"><span class="nav-number">2.3.8.</span> <span class="nav-text">Pre-trained Model</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#PACT-Quantization-1"><span class="nav-number">2.3.9.</span> <span class="nav-text">PACT Quantization</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Experiments"><span class="nav-number">3.</span> <span class="nav-text">Experiments</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#3-1-Experimental-Setup"><span class="nav-number">3.1.</span> <span class="nav-text">3.1 Experimental Setup</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Implementation-Details"><span class="nav-number">3.2.</span> <span class="nav-text">Implementation Details</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">xzbin</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">34</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">30</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">xzbin</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
